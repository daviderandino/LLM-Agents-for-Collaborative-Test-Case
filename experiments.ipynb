{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "491ee08f",
   "metadata": {},
   "source": [
    "# Agents For Test Case Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939bc1b5",
   "metadata": {},
   "source": [
    "## Download repo from Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2870c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "REPO_OWNER = \"daviderandino\"\n",
    "REPO_NAME = \"LLM-Agents-for-Collaborative-Test-Case\"\n",
    "BRANCH = \"experik\"\n",
    "USER_EMAIL = \"erikscolaro31@gmail.com\"\n",
    "USER_NAME = \"erikscolaro\"\n",
    "\n",
    "try:\n",
    "    GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n",
    "    GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
    "    os.environ['GROQ_API_KEY'] = GROQ_API_KEY\n",
    "except userdata.SecretNotFoundError as e:\n",
    "    print(f\"Error: Missing a secret in Colab Secrets: {e}\")\n",
    "\n",
    "if not os.path.exists(REPO_NAME):\n",
    "    print(f\"Cloning repository {REPO_NAME}...\")\n",
    "    clone_url = f\"https://{GITHUB_TOKEN}@github.com/{REPO_OWNER}/{REPO_NAME}.git\"\n",
    "    !git clone {clone_url}\n",
    "    %cd {REPO_NAME}\n",
    "    !git checkout {BRANCH}\n",
    "    \n",
    "    !git config --global user.email {USER_EMAIL}\n",
    "    !git config --global user.name {USER_NAME}\n",
    "    \n",
    "    print(\"Installing dependencies...\")\n",
    "    !pip install -r requirements.txt -q\n",
    "    print(\"Setup completed!\")\n",
    "\n",
    "else:\n",
    "    print(f\"Folder {REPO_NAME} already exists.\")\n",
    "    %cd {REPO_NAME}\n",
    "    print(\"Updating branch...\")\n",
    "    !git pull origin {BRANCH}\n",
    "    print(\"Environment updated and ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec79cbb8",
   "metadata": {},
   "source": [
    "## Upload results and commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea72be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "commit_message = \"Automatic update from Colab\"\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "full_message = f\"{commit_message} - {timestamp}\"\n",
    "\n",
    "print(\"Starting sync procedure...\")\n",
    "\n",
    "!git add .\n",
    "!git commit -m \"{full_message}\" || echo \"No local changes detected, proceeding to pull/push...\"\n",
    "\n",
    "print(\"Pulling remote changes...\")\n",
    "!git pull origin experik --no-rebase --no-edit\n",
    "\n",
    "print(\"Pushing changes to GitHub...\")\n",
    "!git push origin experik\n",
    "\n",
    "print(\"All synchronized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3c8b2d",
   "metadata": {},
   "source": [
    "## Multiple Sequential Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98c1808d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Execution: configs/experiments/competitive_llama70B_natural.yaml\n",
      "================================================================================\n",
      "\n",
      "ğŸ§ª Loading Experiment: configs/experiments/competitive_llama70B_natural.yaml\n",
      "15:08:49 - INFO - Orchestrator - ğŸš€ Starting Experiment. Strategy: competitive_agents_natural\n",
      "15:08:49 - INFO - Orchestrator - ğŸ“‚ Input Path: data/input_code\n",
      "15:08:49 - INFO - Orchestrator - ğŸŒ¡ï¸  Temperature: 0.0\n",
      "15:08:49 - INFO - Orchestrator - ğŸ“ Found 20 file(s) to process.\n",
      "15:08:49 - INFO - Orchestrator - --- Processing: t18.py ---\n",
      "15:08:49 - INFO - Agent - \u001b[36m\n",
      "--- STEP 1.1: PLANNING FROM SCRATCH ---\u001b[0m\n",
      "15:08:51 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:08:51 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:08:51 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:09:01 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:09:01 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 1 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:09:02 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:09:11 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:09:11 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 2 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:09:12 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:09:12 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:09:16 - INFO - Agent - Dev 1 -> Valid: True, Cov: 100%, Fail: 3\n",
      "15:09:16 - INFO - Agent - Dev 2 -> Valid: True, Cov: 0%, Fail: 17\n",
      "15:09:16 - INFO - Agent - \u001b[32mğŸ† WINNER: Dev 1 (Better Coverage)\u001b[0m\n",
      "15:09:16 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:09:16 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:09:26 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:09:26 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 1 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:09:27 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:09:36 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:09:36 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 2 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:09:37 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:09:37 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:09:40 - INFO - Agent - Dev 1 -> Valid: True, Cov: 100%, Fail: 0\n",
      "15:09:40 - INFO - Agent - Dev 2 -> Valid: True, Cov: 100%, Fail: 0\n",
      "15:09:40 - INFO - Agent - \u001b[32mğŸ† WINNER: Dev 1 (Tie-Break Failures)\u001b[0m\n",
      "15:09:40 - INFO - Orchestrator - ğŸ§¬ Running mutation testing...\n",
      "   Mutmut exit code: 14\n",
      "   âŒ Mutmut failed with return code 14\n",
      "   STDOUT: \n",
      "- Mutation testing starting -\n",
      "\n",
      "These are the steps:\n",
      "1. A full test suite run will be made to make sure we\n",
      "   can run the tests successfully and we know how long\n",
      "   it takes (to detect infinite loops for example)\n",
      "2. Mutants will be generated and checked\n",
      "\n",
      "Results are stored in .mutmut-cache.\n",
      "Print found mutants with `mutmut results`.\n",
      "\n",
      "Legend for output:\n",
      "ğŸ‰ Killed mutants.   The goal is for everything to end up in this bucket.\n",
      "â° Timeout.          Test suite took 10 times as long as the baseline so were killed.\n",
      "ğŸ¤” Suspicious.       Tests took a long time, but not long enough to be fatal.\n",
      "ğŸ™ Survived.         This means your tests need to be expanded.\n",
      "ğŸ”‡ Skipped.          Skipped.\n",
      "\n",
      "mutmut cache is out of date, clearing it...\n",
      "1. Running tests without mutations\n",
      "Done\n",
      "\n",
      "2. Checking mutants\n",
      "\n",
      "\n",
      "   STDERR: \n",
      "15:10:53 - INFO - Orchestrator - Metrics for t18.py: {'coverage_percent': 100, 'n_passed_tests': 18, 'n_failed_tests': 0, 'failed_tests_infos': '', 'iterations': 2, 'cost': 0, 'total_tokens': 13284, 'mutation_score_percent': None, 'mutation_killed': None, 'mutation_survived': None}\n",
      "15:10:53 - INFO - Orchestrator - --- Processing: t16.py ---\n",
      "15:10:54 - INFO - Agent - \u001b[36m\n",
      "--- STEP 1.1: PLANNING FROM SCRATCH ---\u001b[0m\n",
      "15:10:55 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:10:55 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:10:55 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:11:05 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:11:05 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 1 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:11:05 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:11:15 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:11:15 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 2 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:11:15 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:11:15 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:11:21 - INFO - Agent - Dev 1 -> Valid: False, Cov: 0%, Fail: 9999\n",
      "15:11:21 - INFO - Agent - Dev 2 -> Valid: False, Cov: 0%, Fail: 9999\n",
      "15:11:21 - INFO - Agent - \u001b[32mğŸ† WINNER: None (Both Crashed)\u001b[0m\n",
      "15:11:21 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:11:21 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:11:31 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:11:31 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 1 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:11:32 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:11:41 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:11:41 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 2 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:11:42 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:11:42 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:11:47 - INFO - Agent - Dev 1 -> Valid: False, Cov: 0%, Fail: 9999\n",
      "15:11:47 - INFO - Agent - Dev 2 -> Valid: False, Cov: 0%, Fail: 9999\n",
      "15:11:47 - INFO - Agent - \u001b[32mğŸ† WINNER: None (Both Crashed)\u001b[0m\n",
      "15:11:47 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:11:47 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:11:57 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:11:57 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 1 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:11:58 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:12:07 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:12:07 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 2 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:12:08 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:12:08 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:12:12 - INFO - Agent - Dev 1 -> Valid: False, Cov: 0%, Fail: 9999\n",
      "15:12:12 - INFO - Agent - Dev 2 -> Valid: False, Cov: 0%, Fail: 9999\n",
      "15:12:12 - INFO - Agent - \u001b[32mğŸ† WINNER: None (Both Crashed)\u001b[0m\n",
      "15:12:12 - INFO - Orchestrator - ğŸ§¹ Cleanup: Removing 9999 failed tests...\n",
      "15:12:15 - INFO - Orchestrator - âœ“ Cleanup complete. New metrics - Coverage: 0%, Passed: 0, Failed: 9999\n",
      "15:12:15 - INFO - Orchestrator - ğŸ§¬ Running mutation testing...\n",
      "   Mutmut exit code: 1\n",
      "15:12:17 - INFO - Orchestrator - Metrics for t16.py: {'coverage_percent': 0, 'n_passed_tests': 0, 'n_failed_tests': 9999, 'failed_tests_infos': '', 'iterations': 3, 'cost': 0, 'total_tokens': 5967, 'mutation_score_percent': 0.0, 'mutation_killed': 0, 'mutation_survived': 0}\n",
      "15:12:17 - INFO - Orchestrator - --- Processing: t15.py ---\n",
      "15:12:17 - INFO - Agent - \u001b[36m\n",
      "--- STEP 1.1: PLANNING FROM SCRATCH ---\u001b[0m\n",
      "15:12:18 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:12:18 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:12:18 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:12:28 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:12:28 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 1 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:12:29 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:12:38 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:12:38 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 2 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:12:39 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:12:39 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:12:43 - INFO - Agent - Dev 1 -> Valid: False, Cov: 0%, Fail: 9999\n",
      "15:12:43 - INFO - Agent - Dev 2 -> Valid: False, Cov: 0%, Fail: 9999\n",
      "15:12:43 - INFO - Agent - \u001b[32mğŸ† WINNER: None (Both Crashed)\u001b[0m\n",
      "15:12:43 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:12:43 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:12:53 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:12:53 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 1 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:12:54 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:13:03 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:13:03 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 2 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:13:04 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:13:04 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:13:07 - INFO - Agent - Dev 1 -> Valid: True, Cov: 100%, Fail: 5\n",
      "15:13:07 - INFO - Agent - Dev 2 -> Valid: True, Cov: 100%, Fail: 5\n",
      "15:13:07 - INFO - Agent - \u001b[32mğŸ† WINNER: Dev 1 (Tie-Break Failures)\u001b[0m\n",
      "15:13:07 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:13:07 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:13:17 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:13:17 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 1 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:13:17 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:13:27 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:13:27 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 2 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:13:27 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:13:27 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:13:31 - INFO - Agent - Dev 1 -> Valid: True, Cov: 100%, Fail: 0\n",
      "15:13:31 - INFO - Agent - Dev 2 -> Valid: True, Cov: 100%, Fail: 0\n",
      "15:13:31 - INFO - Agent - \u001b[32mğŸ† WINNER: Dev 1 (Tie-Break Failures)\u001b[0m\n",
      "15:13:31 - INFO - Orchestrator - ğŸ§¬ Running mutation testing...\n",
      "   Mutmut exit code: 0\n",
      "15:13:34 - INFO - Orchestrator - Metrics for t15.py: {'coverage_percent': 100, 'n_passed_tests': 8, 'n_failed_tests': 0, 'failed_tests_infos': '', 'iterations': 3, 'cost': 0, 'total_tokens': 5893, 'mutation_score_percent': 100.0, 'mutation_killed': 1, 'mutation_survived': 0}\n",
      "15:13:34 - INFO - Orchestrator - --- Processing: t9.py ---\n",
      "15:13:34 - INFO - Agent - \u001b[36m\n",
      "--- STEP 1.1: PLANNING FROM SCRATCH ---\u001b[0m\n",
      "15:13:36 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:13:36 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:13:36 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:13:46 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:13:46 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 1 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:13:46 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:13:56 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:13:56 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 2 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:13:56 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:13:56 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:14:01 - INFO - Agent - Dev 1 -> Valid: True, Cov: 100%, Fail: 3\n",
      "15:14:01 - INFO - Agent - Dev 2 -> Valid: True, Cov: 100%, Fail: 3\n",
      "15:14:01 - INFO - Agent - \u001b[32mğŸ† WINNER: Dev 1 (Tie-Break Failures)\u001b[0m\n",
      "15:14:01 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:14:01 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:14:11 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:14:11 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 1 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:14:12 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:14:21 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:14:21 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 2 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:14:22 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:14:22 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:14:26 - INFO - Agent - Dev 1 -> Valid: True, Cov: 100%, Fail: 0\n",
      "15:14:26 - INFO - Agent - Dev 2 -> Valid: True, Cov: 100%, Fail: 0\n",
      "15:14:26 - INFO - Agent - \u001b[32mğŸ† WINNER: Dev 1 (Tie-Break Failures)\u001b[0m\n",
      "15:14:26 - INFO - Orchestrator - ğŸ§¬ Running mutation testing...\n",
      "   Mutmut exit code: 2\n",
      "15:14:42 - INFO - Orchestrator - Metrics for t9.py: {'coverage_percent': 100, 'n_passed_tests': 10, 'n_failed_tests': 0, 'failed_tests_infos': '', 'iterations': 2, 'cost': 0, 'total_tokens': 4654, 'mutation_score_percent': 66.67, 'mutation_killed': 6, 'mutation_survived': 3}\n",
      "15:14:42 - INFO - Orchestrator - --- Processing: t8.py ---\n",
      "15:14:42 - INFO - Agent - \u001b[36m\n",
      "--- STEP 1.1: PLANNING FROM SCRATCH ---\u001b[0m\n",
      "15:14:43 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:14:43 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:14:43 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:14:53 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:14:53 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 1 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:14:54 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:15:03 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:15:03 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 2 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:15:04 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:15:04 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:15:07 - INFO - Agent - Dev 1 -> Valid: True, Cov: 100%, Fail: 0\n",
      "15:15:07 - INFO - Agent - Dev 2 -> Valid: True, Cov: 100%, Fail: 0\n",
      "15:15:07 - INFO - Agent - \u001b[32mğŸ† WINNER: Dev 1 (Tie-Break Failures)\u001b[0m\n",
      "15:15:07 - INFO - Orchestrator - ğŸ§¬ Running mutation testing...\n",
      "   Mutmut exit code: 0\n",
      "15:15:15 - INFO - Orchestrator - Metrics for t8.py: {'coverage_percent': 100, 'n_passed_tests': 9, 'n_failed_tests': 0, 'failed_tests_infos': '', 'iterations': 1, 'cost': 0, 'total_tokens': 3529, 'mutation_score_percent': 100.0, 'mutation_killed': 4, 'mutation_survived': 0}\n",
      "15:15:15 - INFO - Orchestrator - --- Processing: t12.py ---\n",
      "15:15:15 - INFO - Agent - \u001b[36m\n",
      "--- STEP 1.1: PLANNING FROM SCRATCH ---\u001b[0m\n",
      "15:15:17 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:15:17 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:15:17 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:15:27 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:15:27 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 1 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:15:28 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:15:37 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:15:37 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 2 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:15:38 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:15:38 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:15:40 - INFO - Agent - Dev 1 -> Valid: True, Cov: 100%, Fail: 1\n",
      "15:15:40 - INFO - Agent - Dev 2 -> Valid: True, Cov: 100%, Fail: 1\n",
      "15:15:40 - INFO - Agent - \u001b[32mğŸ† WINNER: Dev 1 (Tie-Break Failures)\u001b[0m\n",
      "15:15:40 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:15:40 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:15:50 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:15:50 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 1 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:15:51 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:16:00 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:16:00 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 2 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:16:02 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:16:02 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:16:05 - INFO - Agent - Dev 1 -> Valid: True, Cov: 100%, Fail: 0\n",
      "15:16:05 - INFO - Agent - Dev 2 -> Valid: True, Cov: 100%, Fail: 0\n",
      "15:16:05 - INFO - Agent - \u001b[32mğŸ† WINNER: Dev 1 (Tie-Break Failures)\u001b[0m\n",
      "15:16:05 - INFO - Orchestrator - ğŸ§¬ Running mutation testing...\n",
      "   Mutmut exit code: 0\n",
      "15:16:09 - INFO - Orchestrator - Metrics for t12.py: {'coverage_percent': 100, 'n_passed_tests': 8, 'n_failed_tests': 0, 'failed_tests_infos': '', 'iterations': 2, 'cost': 0, 'total_tokens': 5849, 'mutation_score_percent': 100.0, 'mutation_killed': 1, 'mutation_survived': 0}\n",
      "15:16:09 - INFO - Orchestrator - --- Processing: t7.py ---\n",
      "15:16:09 - INFO - Agent - \u001b[36m\n",
      "--- STEP 1.1: PLANNING FROM SCRATCH ---\u001b[0m\n",
      "15:16:10 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:16:10 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:16:10 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:16:20 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:16:20 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 1 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:16:21 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:16:30 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:16:30 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 2 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:16:31 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:16:31 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:16:35 - INFO - Agent - Dev 1 -> Valid: False, Cov: 0%, Fail: 9999\n",
      "15:16:35 - INFO - Agent - Dev 2 -> Valid: False, Cov: 0%, Fail: 9999\n",
      "15:16:35 - INFO - Agent - \u001b[32mğŸ† WINNER: None (Both Crashed)\u001b[0m\n",
      "15:16:35 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:16:35 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:16:45 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:16:45 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 1 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:16:46 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:16:55 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:16:55 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 2 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:16:56 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:16:56 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:17:00 - INFO - Agent - Dev 1 -> Valid: True, Cov: 100%, Fail: 6\n",
      "15:17:00 - INFO - Agent - Dev 2 -> Valid: False, Cov: 0%, Fail: 9999\n",
      "15:17:00 - INFO - Agent - \u001b[32mğŸ† WINNER: Dev 1 (Dev 2 Crashed)\u001b[0m\n",
      "15:17:00 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:17:00 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:17:10 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:17:10 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 1 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:17:10 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:17:20 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:17:20 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 2 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:17:20 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:17:20 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:17:23 - INFO - Agent - Dev 1 -> Valid: True, Cov: 100%, Fail: 0\n",
      "15:17:23 - INFO - Agent - Dev 2 -> Valid: True, Cov: 100%, Fail: 0\n",
      "15:17:23 - INFO - Agent - \u001b[32mğŸ† WINNER: Dev 1 (Tie-Break Failures)\u001b[0m\n",
      "15:17:23 - INFO - Orchestrator - ğŸ§¬ Running mutation testing...\n",
      "   Mutmut exit code: 0\n",
      "15:17:27 - INFO - Orchestrator - Metrics for t7.py: {'coverage_percent': 100, 'n_passed_tests': 10, 'n_failed_tests': 0, 'failed_tests_infos': '', 'iterations': 3, 'cost': 0, 'total_tokens': 6174, 'mutation_score_percent': 100.0, 'mutation_killed': 1, 'mutation_survived': 0}\n",
      "15:17:27 - INFO - Orchestrator - --- Processing: t4.py ---\n",
      "15:17:27 - INFO - Agent - \u001b[36m\n",
      "--- STEP 1.1: PLANNING FROM SCRATCH ---\u001b[0m\n",
      "15:17:28 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:17:28 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:17:28 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:17:38 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:17:38 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 1 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:17:39 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:17:48 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:17:48 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 2 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:17:49 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:17:49 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:17:53 - INFO - Agent - Dev 1 -> Valid: True, Cov: 100%, Fail: 0\n",
      "15:17:53 - INFO - Agent - Dev 2 -> Valid: True, Cov: 100%, Fail: 0\n",
      "15:17:53 - INFO - Agent - \u001b[32mğŸ† WINNER: Dev 1 (Tie-Break Failures)\u001b[0m\n",
      "15:17:53 - INFO - Orchestrator - ğŸ§¬ Running mutation testing...\n",
      "   Mutmut exit code: 0\n",
      "15:17:59 - INFO - Orchestrator - Metrics for t4.py: {'coverage_percent': 100, 'n_passed_tests': 10, 'n_failed_tests': 0, 'failed_tests_infos': '', 'iterations': 1, 'cost': 0, 'total_tokens': 3800, 'mutation_score_percent': 100.0, 'mutation_killed': 1, 'mutation_survived': 0}\n",
      "15:17:59 - INFO - Orchestrator - --- Processing: t19.py ---\n",
      "15:17:59 - INFO - Agent - \u001b[36m\n",
      "--- STEP 1.1: PLANNING FROM SCRATCH ---\u001b[0m\n",
      "15:18:00 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:18:00 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:18:00 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:18:10 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:18:10 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 1 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:18:11 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:18:20 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:18:20 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 2 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:18:21 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:18:21 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:18:23 - INFO - Agent - Dev 1 -> Valid: True, Cov: 100%, Fail: 1\n",
      "15:18:23 - INFO - Agent - Dev 2 -> Valid: True, Cov: 100%, Fail: 1\n",
      "15:18:23 - INFO - Agent - \u001b[32mğŸ† WINNER: Dev 1 (Tie-Break Failures)\u001b[0m\n",
      "15:18:23 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:18:23 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:18:33 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:18:33 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 1 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:18:34 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:18:43 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:18:43 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 2 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:18:44 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:18:44 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:18:47 - INFO - Agent - Dev 1 -> Valid: True, Cov: 100%, Fail: 0\n",
      "15:18:47 - INFO - Agent - Dev 2 -> Valid: True, Cov: 100%, Fail: 0\n",
      "15:18:47 - INFO - Agent - \u001b[32mğŸ† WINNER: Dev 1 (Tie-Break Failures)\u001b[0m\n",
      "15:18:47 - INFO - Orchestrator - ğŸ§¬ Running mutation testing...\n",
      "   Mutmut exit code: 0\n",
      "15:18:52 - INFO - Orchestrator - Metrics for t19.py: {'coverage_percent': 100, 'n_passed_tests': 10, 'n_failed_tests': 0, 'failed_tests_infos': '', 'iterations': 2, 'cost': 0, 'total_tokens': 4262, 'mutation_score_percent': 100.0, 'mutation_killed': 2, 'mutation_survived': 0}\n",
      "15:18:52 - INFO - Orchestrator - --- Processing: t3.py ---\n",
      "15:18:52 - INFO - Agent - \u001b[36m\n",
      "--- STEP 1.1: PLANNING FROM SCRATCH ---\u001b[0m\n",
      "15:18:53 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:18:53 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:18:53 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:19:03 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:19:03 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 1 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:19:03 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:19:13 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:19:13 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 2 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:19:13 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:19:13 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:19:16 - INFO - Agent - Dev 1 -> Valid: True, Cov: 100%, Fail: 2\n",
      "15:19:16 - INFO - Agent - Dev 2 -> Valid: True, Cov: 100%, Fail: 3\n",
      "15:19:16 - INFO - Agent - \u001b[32mğŸ† WINNER: Dev 1 (Tie-Break Failures)\u001b[0m\n",
      "15:19:16 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:19:16 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:19:26 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:19:26 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 1 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:19:28 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:19:36 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:19:36 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 2 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:19:38 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:19:38 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:19:41 - INFO - Agent - Dev 1 -> Valid: True, Cov: 100%, Fail: 2\n",
      "15:19:41 - INFO - Agent - Dev 2 -> Valid: True, Cov: 100%, Fail: 2\n",
      "15:19:41 - INFO - Agent - \u001b[32mğŸ† WINNER: Dev 1 (Tie-Break Failures)\u001b[0m\n",
      "15:19:41 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:19:41 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:19:51 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:19:51 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 1 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:19:52 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:20:01 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:20:01 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 2 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:20:02 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:20:02 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:20:05 - INFO - Agent - Dev 1 -> Valid: True, Cov: 100%, Fail: 1\n",
      "15:20:05 - INFO - Agent - Dev 2 -> Valid: True, Cov: 100%, Fail: 1\n",
      "15:20:05 - INFO - Agent - \u001b[32mğŸ† WINNER: Dev 1 (Tie-Break Failures)\u001b[0m\n",
      "15:20:05 - INFO - Orchestrator - ğŸ§¹ Cleanup: Removing 1 failed tests...\n",
      "15:20:07 - INFO - Orchestrator - âœ“ Cleanup complete. New metrics - Coverage: 100%, Passed: 9, Failed: 1\n",
      "15:20:07 - INFO - Orchestrator - ğŸ§¬ Running mutation testing...\n",
      "   Mutmut exit code: 0\n",
      "15:20:22 - INFO - Orchestrator - Metrics for t3.py: {'coverage_percent': 100, 'n_passed_tests': 9, 'n_failed_tests': 1, 'failed_tests_infos': \"FAILED test_is_not_prime_float - Failed: DID NOT RAISE <class 'TypeError'>\", 'iterations': 3, 'cost': 0, 'total_tokens': 6657, 'mutation_score_percent': 100.0, 'mutation_killed': 10, 'mutation_survived': 0}\n",
      "15:20:22 - INFO - Orchestrator - --- Processing: t13.py ---\n",
      "15:20:22 - INFO - Agent - \u001b[36m\n",
      "--- STEP 1.1: PLANNING FROM SCRATCH ---\u001b[0m\n",
      "15:20:24 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:20:24 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:20:24 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:20:34 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:20:34 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 1 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:20:35 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:20:44 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:20:44 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 2 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:20:45 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:20:45 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:20:49 - INFO - Agent - Dev 1 -> Valid: False, Cov: 0%, Fail: 9999\n",
      "15:20:49 - INFO - Agent - Dev 2 -> Valid: False, Cov: 0%, Fail: 9999\n",
      "15:20:49 - INFO - Agent - \u001b[32mğŸ† WINNER: None (Both Crashed)\u001b[0m\n",
      "15:20:49 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:20:49 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:20:59 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:20:59 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 1 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:20:59 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:21:09 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:21:09 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 2 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:21:09 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:21:09 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:21:12 - INFO - Agent - Dev 1 -> Valid: True, Cov: 100%, Fail: 1\n",
      "15:21:12 - INFO - Agent - Dev 2 -> Valid: True, Cov: 100%, Fail: 2\n",
      "15:21:12 - INFO - Agent - \u001b[32mğŸ† WINNER: Dev 1 (Tie-Break Failures)\u001b[0m\n",
      "15:21:12 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:21:12 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:21:22 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:21:22 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 1 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:21:23 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:21:32 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:21:32 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 2 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:21:33 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:21:33 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:21:37 - INFO - Agent - Dev 1 -> Valid: True, Cov: 100%, Fail: 1\n",
      "15:21:37 - INFO - Agent - Dev 2 -> Valid: True, Cov: 100%, Fail: 1\n",
      "15:21:37 - INFO - Agent - \u001b[32mğŸ† WINNER: Dev 1 (Tie-Break Failures)\u001b[0m\n",
      "15:21:37 - INFO - Orchestrator - ğŸ§¹ Cleanup: Removing 1 failed tests...\n",
      "15:21:38 - INFO - Orchestrator - âœ“ Cleanup complete. New metrics - Coverage: 100%, Passed: 7, Failed: 1\n",
      "15:21:38 - INFO - Orchestrator - ğŸ§¬ Running mutation testing...\n",
      "   Mutmut exit code: 2\n",
      "15:21:46 - INFO - Orchestrator - Metrics for t13.py: {'coverage_percent': 100, 'n_passed_tests': 7, 'n_failed_tests': 1, 'failed_tests_infos': \"FAILED test_count_common_non_string_input - AssertionError: assert [('apple', 1), (1, 1), ('banana', 1), (None, 1)] == [(1, 1), (None, 1), ('apple', 1), ('banana', 1)]\", 'iterations': 3, 'cost': 0, 'total_tokens': 7526, 'mutation_score_percent': 66.67, 'mutation_killed': 2, 'mutation_survived': 1}\n",
      "15:21:46 - INFO - Orchestrator - --- Processing: t2.py ---\n",
      "15:21:47 - INFO - Agent - \u001b[36m\n",
      "--- STEP 1.1: PLANNING FROM SCRATCH ---\u001b[0m\n",
      "15:21:48 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:21:48 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:21:48 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:21:58 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:21:58 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 1 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:21:58 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:22:08 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:22:08 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 2 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:22:08 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:22:08 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:22:12 - INFO - Agent - Dev 1 -> Valid: False, Cov: 0%, Fail: 9999\n",
      "15:22:12 - INFO - Agent - Dev 2 -> Valid: False, Cov: 0%, Fail: 9999\n",
      "15:22:12 - INFO - Agent - \u001b[32mğŸ† WINNER: None (Both Crashed)\u001b[0m\n",
      "15:22:12 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:22:12 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:22:22 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:22:22 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 1 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:22:23 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:22:32 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:22:32 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 2 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:22:32 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:22:32 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:22:36 - INFO - Agent - Dev 1 -> Valid: True, Cov: 100%, Fail: 0\n",
      "15:22:36 - INFO - Agent - Dev 2 -> Valid: True, Cov: 100%, Fail: 0\n",
      "15:22:36 - INFO - Agent - \u001b[32mğŸ† WINNER: Dev 1 (Tie-Break Failures)\u001b[0m\n",
      "15:22:36 - INFO - Orchestrator - ğŸ§¬ Running mutation testing...\n",
      "   Mutmut exit code: 0\n",
      "15:22:41 - INFO - Orchestrator - Metrics for t2.py: {'coverage_percent': 100, 'n_passed_tests': 8, 'n_failed_tests': 0, 'failed_tests_infos': '', 'iterations': 2, 'cost': 0, 'total_tokens': 4866, 'mutation_score_percent': 100.0, 'mutation_killed': 2, 'mutation_survived': 0}\n",
      "15:22:41 - INFO - Orchestrator - --- Processing: t17.py ---\n",
      "15:22:41 - INFO - Agent - \u001b[36m\n",
      "--- STEP 1.1: PLANNING FROM SCRATCH ---\u001b[0m\n",
      "15:22:42 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:22:42 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:22:42 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:22:52 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:22:52 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 1 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:22:52 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:23:02 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:23:02 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 2 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:23:02 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:23:02 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:23:05 - INFO - Agent - Dev 1 -> Valid: True, Cov: 100%, Fail: 1\n",
      "15:23:05 - INFO - Agent - Dev 2 -> Valid: True, Cov: 100%, Fail: 1\n",
      "15:23:05 - INFO - Agent - \u001b[32mğŸ† WINNER: Dev 1 (Tie-Break Failures)\u001b[0m\n",
      "15:23:05 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:23:05 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:23:15 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:23:15 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 1 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:23:16 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:23:25 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:23:25 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 2 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:23:26 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:23:26 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:23:29 - INFO - Agent - Dev 1 -> Valid: True, Cov: 100%, Fail: 1\n",
      "15:23:29 - INFO - Agent - Dev 2 -> Valid: True, Cov: 100%, Fail: 1\n",
      "15:23:29 - INFO - Agent - \u001b[32mğŸ† WINNER: Dev 1 (Tie-Break Failures)\u001b[0m\n",
      "15:23:29 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:23:29 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:23:39 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:23:39 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 1 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:23:40 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:23:49 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:23:49 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 2 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:23:50 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:23:50 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:23:53 - INFO - Agent - Dev 1 -> Valid: True, Cov: 100%, Fail: 1\n",
      "15:23:53 - INFO - Agent - Dev 2 -> Valid: True, Cov: 100%, Fail: 1\n",
      "15:23:53 - INFO - Agent - \u001b[32mğŸ† WINNER: Dev 1 (Tie-Break Failures)\u001b[0m\n",
      "15:23:53 - INFO - Orchestrator - ğŸ§¹ Cleanup: Removing 1 failed tests...\n",
      "15:23:54 - INFO - Orchestrator - âœ“ Cleanup complete. New metrics - Coverage: 100%, Passed: 6, Failed: 1\n",
      "15:23:54 - INFO - Orchestrator - ğŸ§¬ Running mutation testing...\n",
      "   Mutmut exit code: 0\n",
      "15:24:00 - INFO - Orchestrator - Metrics for t17.py: {'coverage_percent': 100, 'n_passed_tests': 6, 'n_failed_tests': 1, 'failed_tests_infos': \"FAILED test_square_perimeter_error[five] - Failed: DID NOT RAISE <class 'TypeError'>\", 'iterations': 3, 'cost': 0, 'total_tokens': 5190, 'mutation_score_percent': 100.0, 'mutation_killed': 3, 'mutation_survived': 0}\n",
      "15:24:00 - INFO - Orchestrator - --- Processing: t11.py ---\n",
      "15:24:01 - INFO - Agent - \u001b[36m\n",
      "--- STEP 1.1: PLANNING FROM SCRATCH ---\u001b[0m\n",
      "15:24:02 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:24:02 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:24:02 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:24:12 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:24:12 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 1 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:24:13 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:24:22 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:24:22 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 2 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:24:23 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:24:23 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:24:25 - INFO - Agent - Dev 1 -> Valid: True, Cov: 100%, Fail: 4\n",
      "15:24:25 - INFO - Agent - Dev 2 -> Valid: True, Cov: 100%, Fail: 4\n",
      "15:24:25 - INFO - Agent - \u001b[32mğŸ† WINNER: Dev 1 (Tie-Break Failures)\u001b[0m\n",
      "15:24:25 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:24:25 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:24:35 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:24:35 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 1 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:24:36 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:24:45 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:24:45 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 2 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:24:46 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:24:46 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:24:49 - INFO - Agent - Dev 1 -> Valid: True, Cov: 100%, Fail: 2\n",
      "15:24:49 - INFO - Agent - Dev 2 -> Valid: True, Cov: 100%, Fail: 2\n",
      "15:24:49 - INFO - Agent - \u001b[32mğŸ† WINNER: Dev 1 (Tie-Break Failures)\u001b[0m\n",
      "15:24:49 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:24:49 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:24:59 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:24:59 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 1 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:25:00 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:25:09 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:25:09 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 2 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:25:10 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:25:10 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:25:13 - INFO - Agent - Dev 1 -> Valid: True, Cov: 100%, Fail: 2\n",
      "15:25:13 - INFO - Agent - Dev 2 -> Valid: True, Cov: 100%, Fail: 2\n",
      "15:25:13 - INFO - Agent - \u001b[32mğŸ† WINNER: Dev 1 (Tie-Break Failures)\u001b[0m\n",
      "15:25:13 - INFO - Orchestrator - ğŸ§¹ Cleanup: Removing 2 failed tests...\n",
      "15:25:14 - INFO - Orchestrator - âœ“ Cleanup complete. New metrics - Coverage: 100%, Passed: 9, Failed: 2\n",
      "15:25:14 - INFO - Orchestrator - ğŸ§¬ Running mutation testing...\n",
      "   Mutmut exit code: 2\n",
      "15:25:44 - INFO - Orchestrator - Metrics for t11.py: {'coverage_percent': 100, 'n_passed_tests': 9, 'n_failed_tests': 2, 'failed_tests_infos': 'FAILED test_remove_Occ_error[hello-None] - AssertionError: Expected TypeError to be raised\\nFAILED test_remove_Occ_error[hello-123] - AssertionError: Expected TypeError to be raised', 'iterations': 3, 'cost': 0, 'total_tokens': 6991, 'mutation_score_percent': 90.0, 'mutation_killed': 18, 'mutation_survived': 2}\n",
      "15:25:44 - INFO - Orchestrator - --- Processing: t10.py ---\n",
      "15:25:44 - INFO - Agent - \u001b[36m\n",
      "--- STEP 1.1: PLANNING FROM SCRATCH ---\u001b[0m\n",
      "15:25:46 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:25:46 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:25:46 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:25:56 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:25:56 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 1 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:25:57 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:26:06 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:26:06 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 2 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:26:07 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:26:07 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:26:10 - INFO - Agent - Dev 1 -> Valid: True, Cov: 0%, Fail: 10\n",
      "15:26:10 - INFO - Agent - Dev 2 -> Valid: True, Cov: 0%, Fail: 10\n",
      "15:26:10 - INFO - Agent - \u001b[32mğŸ† WINNER: Dev 1 (Tie-Break Failures)\u001b[0m\n",
      "15:26:10 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:26:10 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:26:20 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:26:20 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 1 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:26:21 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:26:30 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:26:30 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 2 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:26:31 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:26:31 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:26:34 - INFO - Agent - Dev 1 -> Valid: True, Cov: 100%, Fail: 1\n",
      "15:26:34 - INFO - Agent - Dev 2 -> Valid: True, Cov: 100%, Fail: 1\n",
      "15:26:34 - INFO - Agent - \u001b[32mğŸ† WINNER: Dev 1 (Tie-Break Failures)\u001b[0m\n",
      "15:26:34 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:26:34 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:26:44 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:26:44 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 1 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:26:45 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:26:54 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:26:54 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 2 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:26:55 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:26:55 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:26:58 - INFO - Agent - Dev 1 -> Valid: True, Cov: 100%, Fail: 1\n",
      "15:26:58 - INFO - Agent - Dev 2 -> Valid: True, Cov: 100%, Fail: 1\n",
      "15:26:58 - INFO - Agent - \u001b[32mğŸ† WINNER: Dev 1 (Tie-Break Failures)\u001b[0m\n",
      "15:26:58 - INFO - Orchestrator - ğŸ§¹ Cleanup: Removing 1 failed tests...\n",
      "15:27:00 - INFO - Orchestrator - âœ“ Cleanup complete. New metrics - Coverage: 100%, Passed: 9, Failed: 1\n",
      "15:27:00 - INFO - Orchestrator - ğŸ§¬ Running mutation testing...\n",
      "   Mutmut exit code: 0\n",
      "15:27:04 - INFO - Orchestrator - Metrics for t10.py: {'coverage_percent': 100, 'n_passed_tests': 9, 'n_failed_tests': 1, 'failed_tests_infos': \"FAILED test_small_nnum_error_input_type - AssertionError: assert ['e', 'h', 'l'] == []\", 'iterations': 3, 'cost': 0, 'total_tokens': 9107, 'mutation_score_percent': 100.0, 'mutation_killed': 1, 'mutation_survived': 0}\n",
      "15:27:04 - INFO - Orchestrator - --- Processing: t1.py ---\n",
      "15:27:04 - INFO - Agent - \u001b[36m\n",
      "--- STEP 1.1: PLANNING FROM SCRATCH ---\u001b[0m\n",
      "15:27:06 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:27:06 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:27:06 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:27:16 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:27:16 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 1 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:27:18 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:27:26 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:27:26 - INFO - Agent - \u001b[36m--- STEP 2.1: DEV 2 GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "15:27:28 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:27:28 - INFO - Agent - \u001b[36m--- STEP 3: EXECUTING PYTEST & COMPARING CANDIDATES---\u001b[0m\n",
      "15:27:31 - INFO - Agent - Dev 1 -> Valid: True, Cov: 100%, Fail: 7\n",
      "15:27:31 - INFO - Agent - Dev 2 -> Valid: True, Cov: 100%, Fail: 7\n",
      "15:27:31 - INFO - Agent - \u001b[32mğŸ† WINNER: Dev 1 (Tie-Break Failures)\u001b[0m\n",
      "15:27:31 - INFO - Agent - \u001b[33m--- WAITING 10 SECONDS BEFORE DEV 1 ---\u001b[0m\n",
      "15:27:31 - INFO - Agent - \u001b[33m--- WAITING 20 SECONDS BEFORE DEV 2 ---\u001b[0m\n",
      "15:27:41 - INFO - Agent - \u001b[36m--- DEV 1 WORKING ---\u001b[0m\n",
      "15:27:41 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 1 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:27:42 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15:27:51 - INFO - Agent - \u001b[36m--- DEV 2 WORKING ---\u001b[0m\n",
      "15:27:51 - INFO - Agent - \u001b[33m--- STEP 2.2: DEV 2 FIXING FAILED TESTS ---\u001b[0m\n",
      "15:27:51 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "15:27:51 - ERROR - Orchestrator - Failed to process t1.py: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kfrk3haqfmk8hthhy19pf4f6` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99991, Requested 1528. Please try again in 21m52.416s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/einrich99/Progetti/LLM-Agents-for-Collaborative-Test-Case/src/experiment_runner.py\", line 109, in run_experiment\n",
      "    metrics = run_competitive_agents_natural(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/LLM-Agents-for-Collaborative-Test-Case/src/agents/multi_agent_competitive_natural/multi_agent_competitive_runner.py\", line 43, in run_competitive_agents\n",
      "    final_state = agents.invoke()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/LLM-Agents-for-Collaborative-Test-Case/src/agents/multi_agent_competitive_natural/MultiAgentCompetitiveGraph.py\", line 609, in invoke\n",
      "    final_state = self.graph.invoke(self.initial_state, config=config)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/pregel/main.py\", line 3068, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/pregel/main.py\", line 2643, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/pregel/_runner.py\", line 258, in tick\n",
      "    _panic_or_proceed(\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/pregel/_runner.py\", line 520, in _panic_or_proceed\n",
      "    raise exc\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/pregel/_executor.py\", line 80, in done\n",
      "    task.result()\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/concurrent/futures/thread.py\", line 59, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/pregel/_retry.py\", line 42, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/_internal/_runnable.py\", line 656, in invoke\n",
      "    input = context.run(step.invoke, input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/_internal/_runnable.py\", line 400, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/LLM-Agents-for-Collaborative-Test-Case/src/agents/multi_agent_competitive_natural/MultiAgentCompetitiveGraph.py\", line 304, in _gen_wrapper_2\n",
      "    result_code, tokens = self._generation_logic(state, self.llm_generator_2, \"DEV 2\")\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/LLM-Agents-for-Collaborative-Test-Case/src/agents/multi_agent_competitive_natural/MultiAgentCompetitiveGraph.py\", line 475, in _generation_logic\n",
      "    response = chain.invoke(invoke_args)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langchain_core/runnables/base.py\", line 3151, in invoke\n",
      "    input_ = context.run(step.invoke, input_, config)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 398, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 1117, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 927, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 1221, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langchain_groq/chat_models.py\", line 593, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/groq/resources/chat/completions.py\", line 461, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/groq/_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/groq/_base_client.py\", line 1044, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kfrk3haqfmk8hthhy19pf4f6` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99991, Requested 1528. Please try again in 21m52.416s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'developer_2' and id 'ca986da4-800a-254b-3214-7e10d2267c67'\n",
      "15:27:51 - INFO - Orchestrator - --- Processing: t20.py ---\n",
      "15:27:51 - INFO - Agent - \u001b[36m\n",
      "--- STEP 1.1: PLANNING FROM SCRATCH ---\u001b[0m\n",
      "15:27:51 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "15:27:51 - ERROR - Orchestrator - Failed to process t20.py: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kfrk3haqfmk8hthhy19pf4f6` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99990, Requested 581. Please try again in 8m13.344s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/einrich99/Progetti/LLM-Agents-for-Collaborative-Test-Case/src/experiment_runner.py\", line 109, in run_experiment\n",
      "    metrics = run_competitive_agents_natural(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/LLM-Agents-for-Collaborative-Test-Case/src/agents/multi_agent_competitive_natural/multi_agent_competitive_runner.py\", line 43, in run_competitive_agents\n",
      "    final_state = agents.invoke()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/LLM-Agents-for-Collaborative-Test-Case/src/agents/multi_agent_competitive_natural/MultiAgentCompetitiveGraph.py\", line 609, in invoke\n",
      "    final_state = self.graph.invoke(self.initial_state, config=config)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/pregel/main.py\", line 3068, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/pregel/main.py\", line 2643, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/pregel/_runner.py\", line 167, in tick\n",
      "    run_with_retry(\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/pregel/_retry.py\", line 42, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/_internal/_runnable.py\", line 656, in invoke\n",
      "    input = context.run(step.invoke, input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/_internal/_runnable.py\", line 400, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/LLM-Agents-for-Collaborative-Test-Case/src/agents/multi_agent_competitive_natural/MultiAgentCompetitiveGraph.py\", line 187, in _plan_node\n",
      "    response = chain.invoke(invoke_args)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langchain_core/runnables/base.py\", line 3151, in invoke\n",
      "    input_ = context.run(step.invoke, input_, config)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 398, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 1117, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 927, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 1221, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langchain_groq/chat_models.py\", line 593, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/groq/resources/chat/completions.py\", line 461, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/groq/_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/groq/_base_client.py\", line 1044, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kfrk3haqfmk8hthhy19pf4f6` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99990, Requested 581. Please try again in 8m13.344s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'planner' and id 'fe8549aa-ecd5-7011-8206-35d320c91112'\n",
      "15:27:51 - INFO - Orchestrator - --- Processing: t14.py ---\n",
      "15:27:51 - INFO - Agent - \u001b[36m\n",
      "--- STEP 1.1: PLANNING FROM SCRATCH ---\u001b[0m\n",
      "15:27:51 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "15:27:51 - ERROR - Orchestrator - Failed to process t14.py: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kfrk3haqfmk8hthhy19pf4f6` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99990, Requested 570. Please try again in 8m3.84s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/einrich99/Progetti/LLM-Agents-for-Collaborative-Test-Case/src/experiment_runner.py\", line 109, in run_experiment\n",
      "    metrics = run_competitive_agents_natural(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/LLM-Agents-for-Collaborative-Test-Case/src/agents/multi_agent_competitive_natural/multi_agent_competitive_runner.py\", line 43, in run_competitive_agents\n",
      "    final_state = agents.invoke()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/LLM-Agents-for-Collaborative-Test-Case/src/agents/multi_agent_competitive_natural/MultiAgentCompetitiveGraph.py\", line 609, in invoke\n",
      "    final_state = self.graph.invoke(self.initial_state, config=config)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/pregel/main.py\", line 3068, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/pregel/main.py\", line 2643, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/pregel/_runner.py\", line 167, in tick\n",
      "    run_with_retry(\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/pregel/_retry.py\", line 42, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/_internal/_runnable.py\", line 656, in invoke\n",
      "    input = context.run(step.invoke, input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/_internal/_runnable.py\", line 400, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/LLM-Agents-for-Collaborative-Test-Case/src/agents/multi_agent_competitive_natural/MultiAgentCompetitiveGraph.py\", line 187, in _plan_node\n",
      "    response = chain.invoke(invoke_args)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langchain_core/runnables/base.py\", line 3151, in invoke\n",
      "    input_ = context.run(step.invoke, input_, config)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 398, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 1117, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 927, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 1221, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langchain_groq/chat_models.py\", line 593, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/groq/resources/chat/completions.py\", line 461, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/groq/_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/groq/_base_client.py\", line 1044, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kfrk3haqfmk8hthhy19pf4f6` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99990, Requested 570. Please try again in 8m3.84s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'planner' and id '21955a4f-2f09-e00c-bb89-f72204c8e192'\n",
      "15:27:51 - INFO - Orchestrator - --- Processing: t6.py ---\n",
      "15:27:51 - INFO - Agent - \u001b[36m\n",
      "--- STEP 1.1: PLANNING FROM SCRATCH ---\u001b[0m\n",
      "15:27:51 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "15:27:51 - ERROR - Orchestrator - Failed to process t6.py: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kfrk3haqfmk8hthhy19pf4f6` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99990, Requested 593. Please try again in 8m23.712s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/einrich99/Progetti/LLM-Agents-for-Collaborative-Test-Case/src/experiment_runner.py\", line 109, in run_experiment\n",
      "    metrics = run_competitive_agents_natural(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/LLM-Agents-for-Collaborative-Test-Case/src/agents/multi_agent_competitive_natural/multi_agent_competitive_runner.py\", line 43, in run_competitive_agents\n",
      "    final_state = agents.invoke()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/LLM-Agents-for-Collaborative-Test-Case/src/agents/multi_agent_competitive_natural/MultiAgentCompetitiveGraph.py\", line 609, in invoke\n",
      "    final_state = self.graph.invoke(self.initial_state, config=config)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/pregel/main.py\", line 3068, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/pregel/main.py\", line 2643, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/pregel/_runner.py\", line 167, in tick\n",
      "    run_with_retry(\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/pregel/_retry.py\", line 42, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/_internal/_runnable.py\", line 656, in invoke\n",
      "    input = context.run(step.invoke, input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/_internal/_runnable.py\", line 400, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/LLM-Agents-for-Collaborative-Test-Case/src/agents/multi_agent_competitive_natural/MultiAgentCompetitiveGraph.py\", line 187, in _plan_node\n",
      "    response = chain.invoke(invoke_args)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langchain_core/runnables/base.py\", line 3151, in invoke\n",
      "    input_ = context.run(step.invoke, input_, config)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 398, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 1117, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 927, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 1221, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langchain_groq/chat_models.py\", line 593, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/groq/resources/chat/completions.py\", line 461, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/groq/_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/groq/_base_client.py\", line 1044, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kfrk3haqfmk8hthhy19pf4f6` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99990, Requested 593. Please try again in 8m23.712s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'planner' and id '83c9220b-84ce-25f5-11ea-4e8cc7b7c808'\n",
      "15:27:51 - INFO - Orchestrator - --- Processing: t5.py ---\n",
      "15:27:51 - INFO - Agent - \u001b[36m\n",
      "--- STEP 1.1: PLANNING FROM SCRATCH ---\u001b[0m\n",
      "15:27:52 - INFO - httpx - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "15:27:52 - ERROR - Orchestrator - Failed to process t5.py: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kfrk3haqfmk8hthhy19pf4f6` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99990, Requested 669. Please try again in 9m29.376s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/einrich99/Progetti/LLM-Agents-for-Collaborative-Test-Case/src/experiment_runner.py\", line 109, in run_experiment\n",
      "    metrics = run_competitive_agents_natural(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/LLM-Agents-for-Collaborative-Test-Case/src/agents/multi_agent_competitive_natural/multi_agent_competitive_runner.py\", line 43, in run_competitive_agents\n",
      "    final_state = agents.invoke()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/LLM-Agents-for-Collaborative-Test-Case/src/agents/multi_agent_competitive_natural/MultiAgentCompetitiveGraph.py\", line 609, in invoke\n",
      "    final_state = self.graph.invoke(self.initial_state, config=config)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/pregel/main.py\", line 3068, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/pregel/main.py\", line 2643, in stream\n",
      "    for _ in runner.tick(\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/pregel/_runner.py\", line 167, in tick\n",
      "    run_with_retry(\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/pregel/_retry.py\", line 42, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/_internal/_runnable.py\", line 656, in invoke\n",
      "    input = context.run(step.invoke, input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langgraph/_internal/_runnable.py\", line 400, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/Progetti/LLM-Agents-for-Collaborative-Test-Case/src/agents/multi_agent_competitive_natural/MultiAgentCompetitiveGraph.py\", line 187, in _plan_node\n",
      "    response = chain.invoke(invoke_args)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langchain_core/runnables/base.py\", line 3151, in invoke\n",
      "    input_ = context.run(step.invoke, input_, config)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 398, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 1117, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 927, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 1221, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/langchain_groq/chat_models.py\", line 593, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/groq/resources/chat/completions.py\", line 461, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/groq/_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/einrich99/anaconda3/envs/ml/lib/python3.12/site-packages/groq/_base_client.py\", line 1044, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kfrk3haqfmk8hthhy19pf4f6` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99990, Requested 669. Please try again in 9m29.376s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'planner' and id '0385ac34-482a-e444-be09-965dbaca7bee'\n",
      "15:27:52 - INFO - Orchestrator - --- ğŸ Experiment Complete ---\n",
      "ğŸ“Š Results saved to results/competitive_llama70B_natural_2026-01-26T15-08-49.json\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MIEI ESPERIMENTI\n",
    "configs = [\n",
    "    # Single Agent Ablation Studies\n",
    "    #\"configs/experiments/ablative_single_llama8B_t=0.0.yaml\",\n",
    "    #\"configs/experiments/single_llama8B_t=0.2.yaml\",\n",
    "    #\"configs/experiments/single_llama8B_t=0.2.yaml\",\n",
    "    #\"configs/experiments/ablative_single_llama8B_t=0.4.yaml\",\n",
    "    #\"configs/experiments/ablative_single_llama8B_t=0.6.yaml\",\n",
    "    #\"configs/experiments/ablative_single_llama8B_t=0.8.yaml\",    \n",
    "    #\"configs/experiments/ablative_single_llama8B_t=1.0.yaml\",    \n",
    "    #\"configs/experiments/ablative_single_llama8B_t=1.2.yaml\",\n",
    "    \n",
    "    # Collaborative Multi-Agent (JSON-based)\n",
    "    #\"configs/experiments/collaborative_llama8B_json.yaml\",\n",
    "    \n",
    "    # Collaborative Multi-Agent (Natural Language)\n",
    "    #\"configs/experiments/collaborative_llama8B_natural.yaml\",\n",
    "    \n",
    "    # Competitive Multi-Agent (JSON-based)\n",
    "    \"configs/experiments/competitive_llama70B_natural.yaml\",\n",
    "    \n",
    "    # Competitive Multi-Agent (Natural Language)\n",
    "    #\"configs/experiments/competitive_llama8B_natural.yaml\",\n",
    "]\n",
    "\n",
    "for cfg in configs:\n",
    "  print(\"\\n\" + \"=\" * 80 + f\"\\nExecution: {cfg}\\n\" + \"=\" * 80 + \"\\n\")\n",
    "  !python -m src.experiment_runner --config {cfg}\n",
    "  print(\"\\n\" + \"-\" * 80 + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
