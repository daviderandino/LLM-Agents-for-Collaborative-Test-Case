{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "491ee08f",
   "metadata": {},
   "source": [
    "# Agents For Test Case Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83342c79",
   "metadata": {},
   "source": [
    "## Single Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb75c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m src.experiment_runner --config configs/experiments/gpt_based/single_gpt4_baseline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a65acc7",
   "metadata": {},
   "source": [
    "## Multi Agent Collaborative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67be3c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m src.experiment_runner --config configs/experiments/gpt_based/collaborative_strong_generator.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "803e6c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Loading Experiment: configs/experiments/gpt_based/collaborative_strong_planner.yaml\n",
      "2026-01-11 21:10:39,102 - Orchestrator - INFO - üöÄ Starting Experiment. Strategy: collaborative_agents\n",
      "2026-01-11 21:10:39,102 - Orchestrator - INFO - üìÇ Input Path: data/input_code\n",
      "2026-01-11 21:10:39,102 - Orchestrator - INFO - üå°Ô∏è  Temperature: 0.2\n",
      "2026-01-11 21:10:39,102 - Orchestrator - INFO - üìù Found 3 file(s) to process.\n",
      "2026-01-11 21:10:39,102 - Orchestrator - INFO - --- Processing: d03_stack.py ---\n",
      "\u001b[36m\n",
      "--- STEP 1.1: PLANNING FROM SCRATCH ---\u001b[0m\n",
      "2026-01-11 21:10:45,890 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[36m--- STEP 2.1: GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "2026-01-11 21:10:49,985 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[36m--- STEP 3: EXECUTING PYTEST ---\u001b[0m\n",
      "\u001b[32m--- EXECUTION RESULT: Coverage=100% 26 Passed 0 Failed ---\u001b[0m\n",
      "2026-01-11 21:11:02,706 - Orchestrator - INFO - --- Processing: d01_bank_account.py ---\n",
      "\u001b[36m\n",
      "--- STEP 1.1: PLANNING FROM SCRATCH ---\u001b[0m\n",
      "2026-01-11 21:11:08,419 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[36m--- STEP 2.1: GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "2026-01-11 21:11:11,901 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[36m--- STEP 3: EXECUTING PYTEST ---\u001b[0m\n",
      "\u001b[31m--- EXECUTION RESULT: Pytest Crash ---\u001b[0m\n",
      "\u001b[33m--- STEP 2.3: FIXING SYNTAX/PYTEST ERROR ---\u001b[0m\n",
      "2026-01-11 21:11:15,996 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[36m--- STEP 3: EXECUTING PYTEST ---\u001b[0m\n",
      "\u001b[32m--- EXECUTION RESULT: Coverage=100% 28 Passed 0 Failed ---\u001b[0m\n",
      "2026-01-11 21:11:34,542 - Orchestrator - INFO - --- Processing: d02_string_utils.py ---\n",
      "\u001b[36m\n",
      "--- STEP 1.1: PLANNING FROM SCRATCH ---\u001b[0m\n",
      "2026-01-11 21:11:45,592 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[36m--- STEP 2.1: GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "2026-01-11 21:11:49,064 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[36m--- STEP 3: EXECUTING PYTEST ---\u001b[0m\n",
      "\u001b[32m--- EXECUTION RESULT: Coverage=95% 43 Passed 2 Failed ---\u001b[0m\n",
      "\u001b[33m--- STEP 2.2: FIXING FAILED TESTS ---\u001b[0m\n",
      "2026-01-11 21:11:49,916 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-11 21:11:49,916 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 1.000000 seconds\n",
      "2026-01-11 21:11:55,931 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[36m--- STEP 3: EXECUTING PYTEST ---\u001b[0m\n",
      "\u001b[32m--- EXECUTION RESULT: Coverage=95% 45 Passed 0 Failed ---\u001b[0m\n",
      "\u001b[33m--- STEP 1.2: RE-PLANNING (Current Coverage: 95%) ---\u001b[0m\n",
      "2026-01-11 21:11:56,715 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-11 21:11:56,715 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds\n",
      "2026-01-11 21:12:04,124 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[36m--- STEP 2.4: APPENDING NEW TESTS ---\u001b[0m\n",
      "2026-01-11 21:12:04,260 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-11 21:12:04,260 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 9.000000 seconds\n",
      "2026-01-11 21:12:16,388 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[36m--- STEP 3: EXECUTING PYTEST ---\u001b[0m\n",
      "\u001b[32m--- EXECUTION RESULT: Coverage=100% 57 Passed 0 Failed ---\u001b[0m\n",
      "2026-01-11 21:12:39,241 - Orchestrator - INFO - --- üèÅ Experiment Complete ---\n",
      "üìù Appended metrics to results/master_log.csv\n",
      "üìä Results saved to results/collaborative_strong_planner/metrics.json\n"
     ]
    }
   ],
   "source": [
    "!python -m src.experiment_runner --config configs/experiments/gpt_based/collaborative_strong_planner.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69223fe4",
   "metadata": {},
   "source": [
    "## Multi Agent Competitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3386c5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m src.experiment_runner --config configs/experiments/gpt_based/competitive_smart.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm4se_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
