{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "491ee08f",
   "metadata": {},
   "source": [
    "# Agents For Test Case Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83342c79",
   "metadata": {},
   "source": [
    "## Single Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb75c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m src.experiment_runner --config configs/experiments/gpt_based/single_gpt4_baseline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a65acc7",
   "metadata": {},
   "source": [
    "## Multi Agent Collaborative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67be3c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m src.experiment_runner --config configs/experiments/gpt_based/collaborative_strong_generator.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "803e6c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Loading Experiment: configs/experiments/gpt_based/collaborative_strong_planner.yaml\n",
      "2026-01-15 23:41:58,786 - Orchestrator - INFO - üöÄ Starting Experiment. Strategy: collaborative_agents\n",
      "2026-01-15 23:41:58,786 - Orchestrator - INFO - üìÇ Input Path: data/input_code\n",
      "2026-01-15 23:41:58,786 - Orchestrator - INFO - üå°Ô∏è  Temperature: 0.2\n",
      "2026-01-15 23:41:58,786 - Orchestrator - INFO - üìù Found 5 file(s) to process.\n",
      "2026-01-15 23:41:58,786 - Orchestrator - INFO - --- Processing: d10_hotel_reservation.py ---\n",
      "\u001b[36m\n",
      "--- STEP 1.1: PLANNING FROM SCRATCH ---\u001b[0m\n",
      "2026-01-15 23:42:05,140 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[36m--- STEP 2.1: GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "2026-01-15 23:42:12,998 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[36m--- STEP 3: EXECUTING PYTEST ---\u001b[0m\n",
      "\u001b[32m--- EXECUTION RESULT: Coverage=100% 16 Passed 1 Failed ---\u001b[0m\n",
      "\u001b[33m--- STEP 2.2: FIXING FAILED TESTS ---\u001b[0m\n",
      "2026-01-15 23:42:13,727 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-15 23:42:13,727 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 6.000000 seconds\n",
      "2026-01-15 23:42:24,467 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[36m--- STEP 3: EXECUTING PYTEST ---\u001b[0m\n",
      "\u001b[32m--- EXECUTION RESULT: Coverage=100% 17 Passed 0 Failed ---\u001b[0m\n",
      "2026-01-15 23:43:00,269 - Orchestrator - INFO - --- Processing: d07_library.py ---\n",
      "\u001b[36m\n",
      "--- STEP 1.1: PLANNING FROM SCRATCH ---\u001b[0m\n",
      "2026-01-15 23:43:04,791 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[36m--- STEP 2.1: GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "2026-01-15 23:43:09,216 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[36m--- STEP 3: EXECUTING PYTEST ---\u001b[0m\n",
      "\u001b[32m--- EXECUTION RESULT: Coverage=100% 13 Passed 0 Failed ---\u001b[0m\n",
      "2026-01-15 23:43:33,087 - Orchestrator - INFO - --- Processing: d03_stack.py ---\n",
      "\u001b[36m\n",
      "--- STEP 1.1: PLANNING FROM SCRATCH ---\u001b[0m\n",
      "2026-01-15 23:43:40,042 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[36m--- STEP 2.1: GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "2026-01-15 23:43:42,806 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[36m--- STEP 3: EXECUTING PYTEST ---\u001b[0m\n",
      "\u001b[32m--- EXECUTION RESULT: Coverage=100% 16 Passed 0 Failed ---\u001b[0m\n",
      "2026-01-15 23:43:55,399 - Orchestrator - INFO - --- Processing: d01_bank_account.py ---\n",
      "\u001b[36m\n",
      "--- STEP 1.1: PLANNING FROM SCRATCH ---\u001b[0m\n",
      "2026-01-15 23:44:05,539 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[36m--- STEP 2.1: GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "2026-01-15 23:44:09,125 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[36m--- STEP 3: EXECUTING PYTEST ---\u001b[0m\n",
      "\u001b[31m--- EXECUTION RESULT: Syntax Error ---\u001b[0m\n",
      "\u001b[33m--- STEP 2.3: FIXING SYNTAX/PYTEST ERROR ---\u001b[0m\n",
      "2026-01-15 23:44:11,990 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[36m--- STEP 3: EXECUTING PYTEST ---\u001b[0m\n",
      "\u001b[32m--- EXECUTION RESULT: Coverage=100% 25 Passed 1 Failed ---\u001b[0m\n",
      "\u001b[33m--- STEP 2.2: FIXING FAILED TESTS ---\u001b[0m\n",
      "2026-01-15 23:44:12,694 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-15 23:44:12,695 - groq._base_client - INFO - Retrying request to /openai/v1/chat/completions in 8.000000 seconds\n",
      "2026-01-15 23:44:23,970 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[36m--- STEP 3: EXECUTING PYTEST ---\u001b[0m\n",
      "\u001b[32m--- EXECUTION RESULT: Coverage=100% 26 Passed 0 Failed ---\u001b[0m\n",
      "2026-01-15 23:44:42,434 - Orchestrator - INFO - --- Processing: d04_linked_list.py ---\n",
      "\u001b[36m\n",
      "--- STEP 1.1: PLANNING FROM SCRATCH ---\u001b[0m\n",
      "2026-01-15 23:44:47,114 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[36m--- STEP 2.1: GENERATING TESTS FROM SCRATCH---\u001b[0m\n",
      "2026-01-15 23:44:51,075 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[36m--- STEP 3: EXECUTING PYTEST ---\u001b[0m\n",
      "\u001b[32m--- EXECUTION RESULT: Coverage=100% 22 Passed 0 Failed ---\u001b[0m\n",
      "2026-01-15 23:45:30,154 - Orchestrator - INFO - --- üèÅ Experiment Complete ---\n",
      "üìù Appended metrics to results/master_log.csv\n",
      "üìä Results saved to results/collaborative_strong_planner/metrics.json\n"
     ]
    }
   ],
   "source": [
    "!python -m src.experiment_runner --config configs/experiments/gpt_based/collaborative_strong_planner.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69223fe4",
   "metadata": {},
   "source": [
    "## Multi Agent Competitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3386c5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m src.experiment_runner --config configs/experiments/gpt_based/competitive_smart.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e64569f",
   "metadata": {},
   "source": [
    "## GPT-based Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8932b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m src.experiment_runner --config configs/experiments/gpt_based/collaborative_strong_generator.yaml\n",
    "!python -m src.experiment_runner --config configs/experiments/gpt_based/collaborative_strong_planner.yaml\n",
    "!python -m src.experiment_runner --config configs/experiments/gpt_based/collaborative_strong.yaml\n",
    "!python -m src.experiment_runner --config configs/experiments/gpt_based/collaborative_weak.yaml\n",
    "!python -m src.experiment_runner --config configs/experiments/gpt_based/competitive_dumb_planner_smart_workers.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a23742",
   "metadata": {},
   "source": [
    "## Llama-based Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6ec264",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m src.experiment_runner --config configs/experiments/llama_based/collaborative_strong_generator.yaml\n",
    "!python -m src.experiment_runner --config configs/experiments/llama_based/collaborative_strong_planner.yaml\n",
    "!python -m src.experiment_runner --config configs/experiments/llama_based/collaborative_strong.yaml\n",
    "!python -m src.experiment_runner --config configs/experiments/llama_based/collaborative_weak.yaml\n",
    "!python -m src.experiment_runner --config configs/experiments/llama_based/competitive_dumb_planner_smart_workers.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm4se_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
